{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy matplotlib pillow mxnet onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def preprocess(image):\n",
    "    # resize so that the shorter side is 256, maintaining aspect ratio\n",
    "    def image_resize(image, min_len):\n",
    "        image = Image.fromarray(image)\n",
    "        ratio = float(min_len) / min(image.size[0], image.size[1])\n",
    "        if image.size[0] > image.size[1]:\n",
    "            new_size = (int(round(ratio * image.size[0])), min_len)\n",
    "        else:\n",
    "            new_size = (min_len, int(round(ratio * image.size[1])))\n",
    "        image = image.resize(new_size, Image.BILINEAR)\n",
    "        return np.array(image)\n",
    "    image = image_resize(image, 256)\n",
    "\n",
    "    # Crop centered window 224x224\n",
    "    def crop_center(image, crop_w, crop_h):\n",
    "        h, w, c = image.shape\n",
    "        start_x = w//2 - crop_w//2\n",
    "        start_y = h//2 - crop_h//2\n",
    "        return image[start_y:start_y+crop_h, start_x:start_x+crop_w, :]\n",
    "    image = crop_center(image, 224, 224)\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose(2, 0, 1)\n",
    "\n",
    "    # convert the input data into the float32 input\n",
    "    img_data = image.astype('float32')\n",
    "\n",
    "    # normalize\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    for i in range(img_data.shape[0]):\n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "\n",
    "    # add batch channel\n",
    "    norm_img_data = norm_img_data.reshape(1, 3, 224, 224).astype('float32')\n",
    "    return norm_img_data\n",
    "\n",
    "async def get_tensor_from_batch(image_size, img_array, array_expected):\n",
    "    k = 0\n",
    "    #print(len(img_array))\n",
    "    count_images = len(img_array)\n",
    "    array_expected[0] = count_images\n",
    "    \n",
    "    # Create a NumPy array to hold the processed data\n",
    "    process_array = np.empty((count_images, 3, image_size, image_size), dtype=np.float32)\n",
    "    \n",
    "    for i in range(count_images):\n",
    "        element = img_array[i]\n",
    "        data = np.asarray(element)\n",
    "        preprocessed_data = await preprocess(data)\n",
    "        process_array[k, :, :, :] = preprocessed_data\n",
    "        k += 1\n",
    "\n",
    "    return process_array\n",
    "\n",
    "\n",
    "def get_images_array(url_array):\n",
    "    # Send a GET request to the URL\n",
    "    if len(url_array) == 0:\n",
    "        response = requests.get(\"https://picsum.photos/v2/list\")\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the JSON response\n",
    "            data = response.json()\n",
    "\n",
    "            # Initialize an empty list to store the images\n",
    "            images = []\n",
    "\n",
    "            # Loop through the data and download/save the images\n",
    "            for item in data:\n",
    "                download_url = item[\"download_url\"]\n",
    "\n",
    "                # Send a GET request to the image URL\n",
    "                image_response = requests.get(download_url)\n",
    "\n",
    "                # Check if the image request was successful\n",
    "                if image_response.status_code == 200:\n",
    "                    # Open the image using PIL\n",
    "                    img = Image.open(BytesIO(image_response.content))\n",
    "\n",
    "                    # Append the image to the list\n",
    "                    images.append(img)\n",
    "\n",
    "                    # Optionally, save the image to a file\n",
    "                    # img.save(f\"{item['id']}.jpg\")\n",
    "\n",
    "            return images\n",
    "            # Now, you have a list of PIL Image objects in the 'images' variable\n",
    "        else:\n",
    "            print(\"Failed to fetch data from the URL\")\n",
    "    else:\n",
    "        # Initialize an empty list to store the images\n",
    "        images = []\n",
    "        for url in url_array:\n",
    "            image_response = requests.get(url)\n",
    "            # Check if the request was successful\n",
    "            if image_response.status_code == 200:\n",
    "                img = Image.open(BytesIO(image_response.content))\n",
    "\n",
    "                # Append the image to the list\n",
    "                images.append(img)\n",
    "\n",
    "                # Optionally, save the image to a file\n",
    "                # img.save(f\"{item['id']}.jpg\")\n",
    "            else:\n",
    "                print(\"Failed to fetch data from the URL\")\n",
    "        return images\n",
    "        # Now, you have a list of PIL Image objects in the 'images' variable\n",
    "        \n",
    "\n",
    "    # You can access the images from the 'images' list and manipulate them as needed\n",
    "# Post-processing function for ImageNet models\n",
    "\n",
    "\n",
    "def download(content, file_name, content_type):\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def on_download(json_data, file_name):\n",
    "    json_str = json.dumps(json_data)\n",
    "    download(json_str.encode('utf-8'), file_name, 'text/plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# General function to run the ONNX model with a given input tensor\n",
    "async def run_onnx_model(tensor):\n",
    "    # Initialize the ONNX Runtime session\n",
    "    options = ort.SessionOptions()\n",
    "    options.intra_op_num_threads = 1\n",
    "    options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "    options.add_session_config_entry('session.intra_op_thread_affinities', '1')\n",
    "    options.enable_profiling=False\n",
    "    ort_session = ort.InferenceSession(\n",
    "            './model.onnx',\n",
    "            sess_options=options,\n",
    "            providers=['CPUExecutionProvider'])\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    feeds = {input_name: tensor}\n",
    "\n",
    "    # Run the model with the input tensor and get the result\n",
    "    result = ort_session.run(None, feeds)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "# Function to run the ONNX model with a batch of images from URLs\n",
    "async def run_batch_model(image_size, array_expected, url_array, images_array, model_name):\n",
    "    times = {}\n",
    "    start_time = time.time()\n",
    "    time_image_array = time.time()\n",
    "    if len(url_array) == 0:\n",
    "        url_array = url_array = [\"https://i.imgur.com/b0rgmfl.jpg\",\n",
    "                        \"https://i.imgur.com/T0wfmza.jpg\",\n",
    "                        \"https://i.imgur.com/pX4HIwE.jpg\",\n",
    "                        \"https://i.imgur.com/Mh0CzBL.jpg\",\n",
    "                        \"https://i.imgur.com/ShJfWWk.jpg\"]\n",
    "    \n",
    "\n",
    "    print(\"Getting images\")\n",
    "    if len(images_array) == 0:\n",
    "        images_array = get_images_array(url_array)\n",
    "\n",
    "    print(\"Obtained array:\")\n",
    "    print(images_array)\n",
    "\n",
    "    time_image_array_elapsed = time.time() - time_image_array\n",
    "    times[\"images\"] = time_image_array_elapsed\n",
    "    print(\"Time spent fetching images: \", time_image_array_elapsed)\n",
    "\n",
    "    print(\"Getting tensor\")\n",
    "    time_tensor = time.time()\n",
    "    tensor_images = await get_tensor_from_batch(image_size, images_array, array_expected)\n",
    "    time_tensor_elapsed = time.time() - time_tensor\n",
    "    times[\"memory\"] = tensor_images.nbytes\n",
    "    times[\"tensor\"] = time_tensor_elapsed\n",
    "    print(\"Time spent creating tensor from images: \", time_tensor_elapsed)\n",
    "\n",
    "    print(\"Running model\")\n",
    "    time_run_model = time.time()\n",
    "    result = await run_onnx_model(tensor_images)\n",
    "    time_run_model_elapsed = time.time() - time_run_model\n",
    "    times[\"model\"] = time_run_model_elapsed\n",
    "    print(\"Time spent running model: \", time_run_model_elapsed)\n",
    "\n",
    "    finish_time = time.time() - start_time\n",
    "    times[\"total\"] = finish_time\n",
    "    print(\"Total processing time: \", finish_time)\n",
    "    #download_name = model_name + \"-\" + \"Data-Python\" + \".json\"\n",
    "    #on_download(json.dumps(result), download_name)\n",
    "    return times\n",
    "\n",
    "# Define the missing functions get_images_array, get_tensor_from_batch, run_onnx_model, and post_json\n",
    "# These functions will depend on your specific implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "# Function to run benchmark\n",
    "async def run_benchmark(image_size, array_expected, url, urls_array, model_name):\n",
    "    pre_images_array = get_images_array(urls_array)\n",
    "    await run_batch_model(image_size, array_expected, urls_array,pre_images_array, model_name)\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        # Create arrays that will store the JSON data\n",
    "        times_json = []\n",
    "        times_json_avg = []\n",
    "        \n",
    "        # Fetch images based on the URLs\n",
    "        images_array = get_images_array(urls_array)\n",
    "        \n",
    "        # Start the repetitions\n",
    "        for rep in range(1, len(images_array) + 1):\n",
    "            if rep == 21:\n",
    "                break\n",
    "            pre_images_array = images_array[:rep]\n",
    "            print(\"Testing with:\", len(pre_images_array), \"images\")\n",
    "            \n",
    "            # Create JSON for each repetition\n",
    "            times = await run_batch_model(image_size, array_expected, urls_array, pre_images_array, model_name)\n",
    "            times_json.append(times)\n",
    "        \n",
    "        # Save JSON data to a file for processing\n",
    "        print(\"Json Times:\", times_json)\n",
    "        \n",
    "        # Download JSON data\n",
    "        download_name = model_name + \"-\" + \"python\" + str(i) + \".json\"\n",
    "        #on_download(json.dumps(times_json), download_name)\n",
    "        print(\"Download ready\")\n",
    "    \n",
    "    # Calculate and save average times if needed\n",
    "    on_download(times_json_avg, \"avg-\" + model_name + \"-\" + backend + \".json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images\n",
      "Obtained array:\n",
      "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x811 at 0x189FF1ABF90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1300x866 at 0x189E5FC9150>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=637x596 at 0x189FFCFF150>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x750 at 0x189E5FA3590>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=800x546 at 0x189FF081A50>]\n",
      "Time spent fetching images:  6.983261346817017\n",
      "Getting tensor\n",
      "Time spent creating tensor from images:  0.10169816017150879\n",
      "Running model\n",
      "Time spent running model:  1.6638109683990479\n",
      "Total processing time:  8.748770475387573\n"
     ]
    }
   ],
   "source": [
    "result = await run_batch_model(224, [1,3,224,224],'',[],\"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "await run_benchmark(224, [1,3,224,224],'',[],\"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def postprocess(scores):\n",
    "    '''\n",
    "    Postprocessing without mxnet gluon\n",
    "    The function takes scores generated by the network and returns the class IDs in decreasing order\n",
    "    of probability using numpy\n",
    "    '''\n",
    "    \n",
    "    prob = softmax(scores)\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: n03832673 notebook, notebook computer, Probability: 0.776560417188784\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def postprocess2():\n",
    "    # Load labels\n",
    "    with open('labels.txt', 'r') as f:\n",
    "        labels = [line.strip() for line in f]\n",
    "\n",
    "    # Load output data\n",
    "    with open('output.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        # Convert the score data from dictionary to numpy array\n",
    "        scores = np.array(list(data['data'].values()))\n",
    "\n",
    "    # Apply softmax to the scores\n",
    "    probabilities = softmax(scores)\n",
    "\n",
    "    # Get the indices of the scores sorted by probability\n",
    "    sorted_indices = np.argsort(probabilities)[::-1]\n",
    "\n",
    "    # Print the top prediction along with its probability\n",
    "    top_prediction = sorted_indices[0]\n",
    "    print(f\"Class: {labels[top_prediction]}, Probability: {probabilities[top_prediction]}\")\n",
    "\n",
    "postprocess2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tomas\\Documentos\\GitHub\\Motivus-AnteProyecto\\testing-automation\\python\\onnx.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tomas/Documentos/GitHub/Motivus-AnteProyecto/testing-automation/python/onnx.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput.json\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tomas/Documentos/GitHub/Motivus-AnteProyecto/testing-automation/python/onnx.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     result \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_file)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Tomas/Documentos/GitHub/Motivus-AnteProyecto/testing-automation/python/onnx.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m arrayResult \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmap()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "# Import JSON module\n",
    "import json\n",
    " # Opening JSON file\n",
    "with open('output.json') as json_file:\n",
    "    result = json.load(json_file)\n",
    "    \n",
    "arrayResult = result['data'].map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = postprocess(list(result['data'].values()))\n",
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a7b9b952ec8508f46d347af27bfa3a445b43b3864b0f01a4595e6c07b52b582"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
